# Ollama Interface

A web interface for interacting with Ollama AI models, featuring code generation, chat functionality, and multimodal capabilities.

## Features

- ğŸ¤– Dynamic model loading and capability detection
- ğŸ’¬ Interactive chat interface with image support
- ğŸ“ Code generation with syntax highlighting
- ğŸ“ File management and organization
- ğŸ¨ Modern, responsive UI

## Prerequisites

- Python 3.8 or higher
- Ollama installed and running locally

## Installation

1. Clone the repository:
```bash
git clone https://github.com/petraxredrat/ollama-interface.git
cd ollama-interface
```

2. Create and activate a virtual environment:
```bash
python -m venv venv
venv\Scripts\activate  # Windows
source venv/bin/activate  # Linux/Mac
```

3. Install dependencies:
```bash
pip install -r requirements.txt
```

## Usage

1. Start Ollama server:
```bash
ollama serve
```

2. Run the application:
```bash
python run.py
```

3. Open your browser and navigate to:
```
http://localhost:5000
```

## Project Structure

```
ollama-interface/
â”œâ”€â”€ app/
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ routes.py
â”‚   â”œâ”€â”€ static/
â”‚   â”‚   â””â”€â”€ favicon.ico
â”‚   â””â”€â”€ templates/
â”‚       â””â”€â”€ index.html
â”œâ”€â”€ requirements.txt
â”œâ”€â”€ run.py
â”œâ”€â”€ .gitignore
â””â”€â”€ README.md
```

## License

MIT License
